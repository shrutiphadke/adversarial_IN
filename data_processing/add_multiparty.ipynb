{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 128 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/phadke/ONR/ONR/big_data/Twitter/4636722562_Thakur_deepak_s_INC.csv'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "from tld import get_tld\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize()\n",
    "\n",
    "datafiles = glob.glob(\"/home/phadke/ONR/ONR/big_data/Twitter/*.csv\")\n",
    "\n",
    "linkframe = pd.DataFrame(columns=['party','link', 'author'])\n",
    "\n",
    "counter = 0\n",
    "\n",
    "datafiles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiparty = ['_AAP.csv', '_DMK.csv', '_AIADMK.csv']\n",
    "valid_files = []\n",
    "\n",
    "for d in datafiles:\n",
    "    for m in multiparty:\n",
    "        if m in d:\n",
    "            valid_files.append(d)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7476\n",
      "1215\n"
     ]
    }
   ],
   "source": [
    "print(len(datafiles))\n",
    "print(len(valid_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n"
     ]
    }
   ],
   "source": [
    "for d in valid_files:\n",
    "    if counter%100==0:\n",
    "        print(counter)\n",
    "    counter+=1\n",
    "    splitfilename = d.replace(\".csv\", \"\").split(\"_\")\n",
    "    party = splitfilename[len(splitfilename)-1]\n",
    "    author = splitfilename[len(splitfilename)-2]\n",
    "    with open(d, \"r\") as jsonfile:\n",
    "\n",
    "        for line in jsonfile:\n",
    "            job= json.loads(line)\n",
    "            if \"entities\" in job.keys():\n",
    "                if \"urls\" in job[\"entities\"]:\n",
    "                    for u in job[\"entities\"][\"urls\"]:\n",
    "                        if \"expanded_url\" in u:\n",
    "                            linkframe = linkframe.append({\"party\":party, \"link\":u[\"expanded_url\"], \"author\":author}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(linkframe.head())\n",
    "\n",
    "linkframe.to_csv(\"/home/phadke/ONR/ONR/lite_data/aap_dec15_nonfiltered_extracted_urls.csv\")\n",
    "## extract domains\n",
    "\n",
    "def get_domain(link):\n",
    "    try:\n",
    "        res = get_tld(link, as_object=True)\n",
    "        return res.fld\n",
    "    except:\n",
    "        fakevar=1\n",
    "\n",
    "\n",
    "linkframe['domain'] = linkframe['link'].parallel_apply(lambda x: get_domain(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(linkframe.head())\n",
    "\n",
    "common_domains = ['twitter.com', 'facebook.com', 'google.com', 'm.tech', 'm.sc', 'b.tech', 'page.link', 'youtu.be', 'bit.ly', 'instagram.com','youtube.com']\n",
    "\n",
    "filtered_link = linkframe.loc[~linkframe['domain'].isin(common_domains)]\n",
    "\n",
    "filtered_link.to_csv(\"/home/phadke/ONR/ONR/lite_data/aap_dec15_filtered_extracted_urls.csv\")\n",
    "\n",
    "agg_filtered = filtered_link.groupby(['author','domain']).size().reset_index().rename(columns={0:\"count\"})\n",
    "\n",
    "print(agg_filtered.head())\n",
    "\n",
    "agg_filtered.to_csv(\"/home/phadke/ONR/ONR/lite_data/aap_dec15_extracted_domains.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_filtered.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(agg_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
