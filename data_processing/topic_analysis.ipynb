{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 128 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "import glob\n",
    "import json\n",
    "from random import sample\n",
    "import sklearn\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize()\n",
    "\n",
    "datafiles = glob.glob(\"/home/phadke/ONR/ONR/big_data/Twitter/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plist = ['_BJP.csv', '_INC.csv', '_AAP.csv']\n",
    "pcount = defaultdict(list)\n",
    "for d in datafiles:\n",
    "    for p in plist:\n",
    "        if p in d:\n",
    "            pcount[p].append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_INC.csv 3006\n",
      "_AAP.csv 430\n",
      "_BJP.csv 3255\n"
     ]
    }
   ],
   "source": [
    "for p in pcount.keys():\n",
    "    print(p, len(pcount[p]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_files = defaultdict(list)\n",
    "for p in pcount:\n",
    "    final_files[p] = sample(pcount[p], 430)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_INC.csv 430\n",
      "_AAP.csv 430\n",
      "_BJP.csv 430\n"
     ]
    }
   ],
   "source": [
    "for p in final_files.keys():\n",
    "    print(p, len(final_files[p]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read randomly sampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowlist = []\n",
    "for p in final_files.keys():\n",
    "    party = p.replace(\"_\", \"\").replace(\".csv\", \"\")\n",
    "    for d in final_files[p]:\n",
    "        with open(d, \"r\") as jsonfile:\n",
    "            for line in jsonfile:\n",
    "                job= json.loads(line)\n",
    "                if \"text\" in job:\n",
    "                    text = job['text']\n",
    "                else:\n",
    "                    text = None\n",
    "                if \"screen_name\" in job:\n",
    "                    sn = job['screen_name']\n",
    "                else:\n",
    "                    sn = None\n",
    "                    \n",
    "                if \"lang\" in job:\n",
    "                    language = job['lang']\n",
    "                else:\n",
    "                    language = None\n",
    "                    \n",
    "                row = [sn, text, party, language]\n",
    "                rowlist.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(rowlist, columns=['screen_name','text','party', 'language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>party</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>संगठन के निर्देशा अनुसार आज रामबाग मण्डल में स...</td>\n",
       "      <td>INC</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>भाजपा युवा मोर्चा की राष्ट्रीय उपाध्यक्षा @The...</td>\n",
       "      <td>INC</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>RT @Amit_BJYM_: जिला आगरा की फतेहपुर सीकरी विध...</td>\n",
       "      <td>INC</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>सहज सरल स्वभाव के धनी, कुशल संगठनकर्ता, कार्यक...</td>\n",
       "      <td>INC</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>विश्व की सबसे बड़ी पार्टी से जुड़ने के लिए 750...</td>\n",
       "      <td>INC</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  screen_name                                               text party  \\\n",
       "0        None  संगठन के निर्देशा अनुसार आज रामबाग मण्डल में स...   INC   \n",
       "1        None  भाजपा युवा मोर्चा की राष्ट्रीय उपाध्यक्षा @The...   INC   \n",
       "2        None  RT @Amit_BJYM_: जिला आगरा की फतेहपुर सीकरी विध...   INC   \n",
       "3        None  सहज सरल स्वभाव के धनी, कुशल संगठनकर्ता, कार्यक...   INC   \n",
       "4        None  विश्व की सबसे बड़ी पार्टी से जुड़ने के लिए 750...   INC   \n",
       "\n",
       "  language  \n",
       "0       hi  \n",
       "1       hi  \n",
       "2       hi  \n",
       "3       hi  \n",
       "4       hi  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>party</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1045400</th>\n",
       "      <td>Pankaj_speak94</td>\n",
       "      <td>RT @SahilVastad: मुस्लिम आंदोलन करत असतील तर त...</td>\n",
       "      <td>AAP</td>\n",
       "      <td>mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365422</th>\n",
       "      <td>None</td>\n",
       "      <td>1. Ideas and innovation,\\n2. जोख़िम लेना,\\n3. ...</td>\n",
       "      <td>BJP</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500508</th>\n",
       "      <td>vardhan08</td>\n",
       "      <td>Today is the 2nd anniversary of Balakot Air st...</td>\n",
       "      <td>BJP</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675617</th>\n",
       "      <td>Vaibhav_AAP</td>\n",
       "      <td>UP मे प्राइवेट स्कूलों के बाहर विरोध प्रदर्शन ...</td>\n",
       "      <td>AAP</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023863</th>\n",
       "      <td>honeychd82</td>\n",
       "      <td>RT @Tractor2twitr: Today’s hashtag is:\\n\\n#Far...</td>\n",
       "      <td>AAP</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            screen_name                                               text  \\\n",
       "1045400  Pankaj_speak94  RT @SahilVastad: मुस्लिम आंदोलन करत असतील तर त...   \n",
       "1365422            None  1. Ideas and innovation,\\n2. जोख़िम लेना,\\n3. ...   \n",
       "1500508       vardhan08  Today is the 2nd anniversary of Balakot Air st...   \n",
       "675617      Vaibhav_AAP  UP मे प्राइवेट स्कूलों के बाहर विरोध प्रदर्शन ...   \n",
       "1023863      honeychd82  RT @Tractor2twitr: Today’s hashtag is:\\n\\n#Far...   \n",
       "\n",
       "        party language  \n",
       "1045400   AAP       mr  \n",
       "1365422   BJP       hi  \n",
       "1500508   BJP       en  \n",
       "675617    AAP       hi  \n",
       "1023863   AAP       en  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = frame.dropna(subset=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = []\n",
    "\n",
    "stopwordfiles = glob.glob(\"../lite_data/stopwords/*.txt\")\n",
    "for s in stopwordfiles:\n",
    "    with open(s, \"r\") as sfile:\n",
    "        for line in sfile:\n",
    "            stopwords.append(line.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['अधिक', 'अनेक', 'अशी', 'असलयाचे', 'असलेल्या', 'असा', 'असून', 'असे', 'आज', 'आणि', 'आता', 'आपल्या', 'आला', 'आली', 'आले', 'आहे', 'आहेत', 'एक', 'एका', 'कमी', 'करणयात', 'करून', 'का', 'काम', 'काय', 'काही', 'किवा', 'की', 'केला', 'केली', 'केले', 'कोटी', 'गेल्या', 'घेऊन', 'जात', 'झाला', 'झाली', 'झाले', 'झालेल्या', 'टा', 'डॉ', 'तर', 'तरी', 'तसेच', 'ता', 'ती', 'तीन', 'ते', 'तो', 'त्या', 'त्याचा', 'त्याची', 'त्याच्या', 'त्याना', 'त्यानी', 'त्यामुळे', 'त्री', 'दिली', 'दोन', 'न', 'नाही', 'निर्ण्य', 'पण', 'पम', 'परयतन', 'पाटील', 'म', 'मात्र', 'माहिती', 'मी', 'मुबी', 'म्हणजे', 'म्हणाले', 'म्हणून', 'या', 'याचा', 'याची', 'याच्या', 'याना', 'यानी', 'येणार', 'येत', 'येथील', 'येथे', 'लाख', 'व', 'व्यकत', 'सर्व', 'सागित्ले', 'सुरू', 'हजार', 'हा', 'ही', 'हे', 'होणार', 'होत', 'होता', 'होती', 'होते', 'शुभेच्छा', 'यांच्या', 'यांना', 'महाराष्ट्र', 'आदमी', 'आम', 'हार्दिक', 'श्री', 'सरकार', 'जी', 'यांनी', 'मा', 'मंत्री', 'अभिवादन', 'काँग्रेस', 'विनम्र', 'करण्यात', 'वाढदिवसाच्या', 'पार्टी', 'च्या', 'भारतीय', 'चे', 'राज्य', 'मध्ये', 'माजी', 'मुख्यमंत्री', 'यांची', 'मुंबई', 'नेते', 'सरकारने', 'अध्यक्ष', 'राष्ट्रीय', 'साहेब', 'कोरोना', 'आमदार', 'शेतकरी', 'जिल्हा', 'प्रदेश', 'करत', 'त्यांच्या', 'ठाकरे', 'मनःपूर्वक', 'जनता', 'भाजपा', 'निमित्त', 'यांचे', 'वीज', 'आपण', 'भेट', 'आघाडी', 'अंदर', 'अत', 'अदि', 'अप', 'अपना', 'अपनि', 'अपनी', 'अपने', 'अभि', 'अभी', 'आदि', 'आप', 'इंहिं', 'इंहें', 'इंहों', 'इतयादि', 'इत्यादि', 'इन', 'इनका', 'इन्हीं', 'इन्हें', 'इन्हों', 'इस', 'इसका', 'इसकि', 'इसकी', 'इसके', 'इसमें', 'इसि', 'इसी', 'इसे', 'उंहिं', 'उंहें', 'उंहों', 'उन', 'उनका', 'उनकि', 'उनकी', 'उनके', 'उनको', 'उन्हीं', 'उन्हें', 'उन्हों', 'उस', 'उसके', 'उसि', 'उसी', 'उसे', 'एक', 'एवं', 'एस', 'एसे', 'ऐसे', 'ओर', 'और', 'कइ', 'कई', 'कर', 'करता', 'करते', 'करना', 'करने', 'करें', 'कहते', 'कहा', 'का', 'काफि', 'काफ़ी', 'कि', 'किंहें', 'किंहों', 'कितना', 'किन्हें', 'किन्हों', 'किया', 'किर', 'किस', 'किसि', 'किसी', 'किसे', 'की', 'कुछ', 'कुल', 'के', 'को', 'कोइ', 'कोई', 'कोन', 'कोनसा', 'कौन', 'कौनसा', 'गया', 'घर', 'जब', 'जहाँ', 'जहां', 'जा', 'जिंहें', 'जिंहों', 'जितना', 'जिधर', 'जिन', 'जिन्हें', 'जिन्हों', 'जिस', 'जिसे', 'जीधर', 'जेसा', 'जेसे', 'जैसा', 'जैसे', 'जो', 'तक', 'तब', 'तरह', 'तिंहें', 'तिंहों', 'तिन', 'तिन्हें', 'तिन्हों', 'तिस', 'तिसे', 'तो', 'था', 'थि', 'थी', 'थे', 'दबारा', 'दवारा', 'दिया', 'दुसरा', 'दुसरे', 'दूसरे', 'दो', 'द्वारा', 'न', 'नहिं', 'नहीं', 'ना', 'निचे', 'निहायत', 'नीचे', 'ने', 'पर', 'पहले', 'पुरा', 'पूरा', 'पे', 'फिर', 'बनि', 'बनी', 'बहि', 'बही', 'बहुत', 'बाद', 'बाला', 'बिलकुल', 'भि', 'भितर', 'भी', 'भीतर', 'मगर', 'मानो', 'मे', 'में', 'यदि', 'यह', 'यहाँ', 'यहां', 'यहि', 'यही', 'या', 'यिह', 'ये', 'रखें', 'रवासा', 'रहा', 'रहे', 'ऱ्वासा', 'लिए', 'लिये', 'लेकिन', 'व', 'वगेरह', 'वरग', 'वर्ग', 'वह', 'वहाँ', 'वहां', 'वहिं', 'वहीं', 'वाले', 'वुह', 'वे', 'वग़ैरह', 'संग', 'सकता', 'सकते', 'सबसे', 'सभि', 'सभी', 'साथ', 'साबुत', 'साभ', 'सारा', 'से', 'सो', 'हि', 'ही', 'हुअ', 'हुआ', 'हुइ', 'हुई', 'हुए', 'हे', 'हें', 'है', 'हैं', 'हो', 'होता', 'होति', 'होती', 'होते', 'होना', 'होने', 'हूँ', 'होगी', 'जी', 'सरकार', 'श्री', 'देश', 'दिल्ली', 'भाजपा', 'प्रदेश', 'भारत', 'मोदी', 'रही', 'कांग्रेस', 'हार्दिक', 'जनता', 'शुभकामनाएं', 'अब', 'पार्टी', 'कोरोना', 'हम', 'किसान', 'क्या', 'किसानों', 'मुख्यमंत्री', 'लोगों', 'हर', 'बधाई', 'प्रधानमंत्री', 'मंत्री', 'नही', 'अध्यक्ष', 'मैं', 'जय', 'वो', 'आम', 'हमारे', 'बात', 'दिन', 'भारतीय', 'आदमी', 'साल', 'नमन', 'सिंह', 'करोड़', 'पूर्व', 'नेता', 'भाई', 'राष्ट्रीय', 'जन्मदिन', 'लेकर', 'गई', 'गए', 'a', 'able', 'about', 'above', 'abst', 'accordance', 'according', 'accordingly', 'across', 'act', 'actually', 'added', 'adj', 'affected', 'affecting', 'affects', 'after', 'afterwards', 'again', 'against', 'ah', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'an', 'and', 'announce', 'another', 'any', 'anybody', 'anyhow', 'anymore', 'anyone', 'anything', 'anyway', 'anyways', 'anywhere', 'apparently', 'approximately', 'are', 'aren', 'arent', 'arise', 'around', 'as', 'aside', 'ask', 'asking', 'at', 'auth', 'available', 'away', 'awfully', 'b', 'back', 'be', 'became', 'because', 'become', 'becomes', 'becoming', 'been', 'before', 'beforehand', 'begin', 'beginning', 'beginnings', 'begins', 'behind', 'being', 'believe', 'below', 'beside', 'besides', 'between', 'beyond', 'biol', 'both', 'brief', 'briefly', 'but', 'by', 'c', 'ca', 'came', 'can', 'cannot', \"can't\", 'cause', 'causes', 'certain', 'certainly', 'co', 'com', 'come', 'comes', 'contain', 'containing', 'contains', 'could', 'couldnt', 'd', 'date', 'did', \"didn't\", 'different', 'do', 'does', \"doesn't\", 'doing', 'done', \"don't\", 'down', 'downwards', 'due', 'during', 'e', 'each', 'ed', 'edu', 'effect', 'eg', 'eight', 'eighty', 'either', 'else', 'elsewhere', 'end', 'ending', 'enough', 'especially', 'et', 'et-al', 'etc', 'even', 'ever', 'every', 'everybody', 'everyone', 'everything', 'everywhere', 'ex', 'except', 'f', 'far', 'few', 'ff', 'fifth', 'first', 'five', 'fix', 'followed', 'following', 'follows', 'for', 'former', 'formerly', 'forth', 'found', 'four', 'from', 'further', 'furthermore', 'g', 'gave', 'get', 'gets', 'getting', 'give', 'given', 'gives', 'giving', 'go', 'goes', 'gone', 'got', 'gotten', 'h', 'had', 'happens', 'hardly', 'has', \"hasn't\", 'have', \"haven't\", 'having', 'he', 'hed', 'hence', 'her', 'here', 'hereafter', 'hereby', 'herein', 'heres', 'hereupon', 'hers', 'herself', 'hes', 'hi', 'hid', 'him', 'himself', 'his', 'hither', 'home', 'how', 'howbeit', 'however', 'hundred', 'i', 'id', 'ie', 'if', \"i'll\", 'im', 'immediate', 'immediately', 'importance', 'important', 'in', 'inc', 'indeed', 'index', 'information', 'instead', 'into', 'invention', 'inward', 'is', \"isn't\", 'it', 'itd', \"it'll\", 'its', 'itself', \"i've\", 'j', 'just', 'k', 'keep', 'keeps', 'kept', 'kg', 'km', 'know', 'known', 'knows', 'l', 'largely', 'last', 'lately', 'later', 'latter', 'latterly', 'least', 'less', 'lest', 'let', 'lets', 'like', 'liked', 'likely', 'line', 'little', \"'ll\", 'look', 'looking', 'looks', 'ltd', 'm', 'made', 'mainly', 'make', 'makes', 'many', 'may', 'maybe', 'me', 'mean', 'means', 'meantime', 'meanwhile', 'merely', 'mg', 'might', 'million', 'miss', 'ml', 'more', 'moreover', 'most', 'mostly', 'mr', 'mrs', 'much', 'mug', 'must', 'my', 'myself', 'n', 'na', 'name', 'namely', 'nay', 'nd', 'near', 'nearly', 'necessarily', 'necessary', 'need', 'needs', 'neither', 'never', 'nevertheless', 'new', 'next', 'nine', 'ninety', 'no', 'nobody', 'non', 'none', 'nonetheless', 'noone', 'nor', 'normally', 'nos', 'not', 'noted', 'nothing', 'now', 'nowhere', 'o', 'obtain', 'obtained', 'obviously', 'of', 'off', 'often', 'oh', 'ok', 'okay', 'old', 'omitted', 'on', 'once', 'one', 'ones', 'only', 'onto', 'or', 'ord', 'other', 'others', 'otherwise', 'ought', 'our', 'ours', 'ourselves', 'out', 'outside', 'over', 'overall', 'owing', 'own', 'p', 'page', 'pages', 'part', 'particular', 'particularly', 'past', 'per', 'perhaps', 'placed', 'please', 'plus', 'poorly', 'possible', 'possibly', 'potentially', 'pp', 'predominantly', 'present', 'previously', 'primarily', 'probably', 'promptly', 'proud', 'provides', 'put', 'q', 'que', 'quickly', 'quite', 'qv', 'r', 'ran', 'rather', 'rd', 're', 'readily', 'really', 'recent', 'recently', 'ref', 'refs', 'regarding', 'regardless', 'regards', 'related', 'relatively', 'research', 'respectively', 'resulted', 'resulting', 'results', 'right', 'run', 's', 'said', 'same', 'saw', 'say', 'saying', 'says', 'sec', 'section', 'see', 'seeing', 'seem', 'seemed', 'seeming', 'seems', 'seen', 'self', 'selves', 'sent', 'seven', 'several', 'shall', 'she', 'shed', \"she'll\", 'shes', 'should', \"shouldn't\", 'show', 'showed', 'shown', 'showns', 'shows', 'significant', 'significantly', 'similar', 'similarly', 'since', 'six', 'slightly', 'so', 'some', 'somebody', 'somehow', 'someone', 'somethan', 'something', 'sometime', 'sometimes', 'somewhat', 'somewhere', 'soon', 'sorry', 'specifically', 'specified', 'specify', 'specifying', 'still', 'stop', 'strongly', 'sub', 'substantially', 'successfully', 'such', 'sufficiently', 'suggest', 'sup', 'sure', 't', 'take', 'taken', 'taking', 'tell', 'tends', 'th', 'than', 'thank', 'thanks', 'thanx', 'that', \"that'll\", 'thats', \"that've\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'thence', 'there', 'thereafter', 'thereby', 'thered', 'therefore', 'therein', \"there'll\", 'thereof', 'therere', 'theres', 'thereto', 'thereupon', \"there've\", 'these', 'they', 'theyd', \"they'll\", 'theyre', \"they've\", 'think', 'this', 'those', 'thou', 'though', 'thoughh', 'thousand', 'throug', 'through', 'throughout', 'thru', 'thus', 'til', 'tip', 'to', 'together', 'too', 'took', 'toward', 'towards', 'tried', 'tries', 'truly', 'try', 'trying', 'ts', 'twice', 'two', 'u', 'un', 'under', 'unfortunately', 'unless', 'unlike', 'unlikely', 'until', 'unto', 'up', 'upon', 'ups', 'us', 'use', 'used', 'useful', 'usefully', 'usefulness', 'uses', 'using', 'usually', 'v', 'value', 'various', \"'ve\", 'very', 'via', 'viz', 'vol', 'vols', 'vs', 'w', 'want', 'wants', 'was', 'wasnt', 'way', 'we', 'wed', 'welcome', \"we'll\", 'went', 'were', 'werent', \"we've\", 'what', 'whatever', \"what'll\", 'whats', 'when', 'whence', 'whenever', 'where', 'whereafter', 'whereas', 'whereby', 'wherein', 'wheres', 'whereupon', 'wherever', 'whether', 'which', 'while', 'whim', 'whither', 'who', 'whod', 'whoever', 'whole', \"who'll\", 'whom', 'whomever', 'whos', 'whose', 'why', 'widely', 'willing', 'wish', 'with', 'within', 'without', 'wont', 'words', 'world', 'would', 'wouldnt', 'www', 'x', 'y', 'yes', 'yet', 'you', 'youd', \"you'll\", 'your', 'youre', 'yours', 'yourself', 'yourselves', \"you've\", 'z', 'zero', \"a's\", 'able', 'about', 'above', 'according', 'accordingly', 'across', 'actually', 'after', 'afterwards', 'again', 'against', \"ain't\", 'all', 'allow', 'allows', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'an', 'and', 'another', 'any', 'anybody', 'anyhow', 'anyone', 'anything', 'anyway', 'anyways', 'anywhere', 'apart', 'appear', 'appreciate', 'appropriate', 'are', \"aren't\", 'around', 'as', 'aside', 'ask', 'asking', 'associated', 'at', 'available', 'away', 'awfully', 'be', 'became', 'because', 'become', 'becomes', 'becoming', 'been', 'before', 'beforehand', 'behind', 'being', 'believe', 'below', 'beside', 'besides', 'best', 'better', 'between', 'beyond', 'both', 'brief', 'but', 'by', \"c'mon\", \"c's\", 'came', 'can', \"can't\", 'cannot', 'cant', 'cause', 'causes', 'certain', 'certainly', 'changes', 'clearly', 'co', 'com', 'come', 'comes', 'concerning', 'consequently', 'consider', 'considering', 'contain', 'containing', 'contains', 'corresponding', 'could', \"couldn't\", 'course', 'currently', 'definitely', 'described', 'despite', 'did', \"didn't\", 'different', 'do', 'does', \"doesn't\", 'doing', \"don't\", 'done', 'down', 'downwards', 'during', 'each', 'edu', 'eg', 'eight', 'either', 'else', 'elsewhere', 'enough', 'entirely', 'especially', 'et', 'etc', 'even', 'ever', 'every', 'everybody', 'everyone', 'everything', 'everywhere', 'ex', 'exactly', 'example', 'except', 'far', 'few', 'fifth', 'first', 'five', 'followed', 'following', 'follows', 'for', 'former', 'formerly', 'forth', 'four', 'from', 'further', 'furthermore', 'get', 'gets', 'getting', 'given', 'gives', 'go', 'goes', 'going', 'gone', 'got', 'gotten', 'greetings', 'had', \"hadn't\", 'happens', 'hardly', 'has', \"hasn't\", 'have', \"haven't\", 'having', 'he', \"he's\", 'hello', 'help', 'hence', 'her', 'here', \"here's\", 'hereafter', 'hereby', 'herein', 'hereupon', 'hers', 'herself', 'hi', 'him', 'himself', 'his', 'hither', 'hopefully', 'how', 'howbeit', 'however', \"i'd\", \"i'll\", \"i'm\", \"i've\", 'ie', 'if', 'ignored', 'immediate', 'in', 'inasmuch', 'inc', 'indeed', 'indicate', 'indicated', 'indicates', 'inner', 'insofar', 'instead', 'into', 'inward', 'is', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', 'just', 'keep', 'keeps', 'kept', 'know', 'known', 'knows', 'last', 'lately', 'later', 'latter', 'latterly', 'least', 'less', 'lest', 'let', \"let's\", 'like', 'liked', 'likely', 'little', 'look', 'looking', 'looks', 'ltd', 'mainly', 'many', 'may', 'maybe', 'me', 'mean', 'meanwhile', 'merely', 'might', 'more', 'moreover', 'most', 'mostly', 'much', 'must', 'my', 'myself', 'name', 'namely', 'nd', 'near', 'nearly', 'necessary', 'need', 'needs', 'neither', 'never', 'nevertheless', 'new', 'next', 'nine', 'no', 'nobody', 'non', 'none', 'noone', 'nor', 'normally', 'not', 'nothing', 'novel', 'now', 'nowhere', 'obviously', 'of', 'off', 'often', 'oh', 'ok', 'okay', 'old', 'on', 'once', 'one', 'ones', 'only', 'onto', 'or', 'other', 'others', 'otherwise', 'ought', 'our', 'ours', 'ourselves', 'out', 'outside', 'over', 'overall', 'own', 'particular', 'particularly', 'per', 'perhaps', 'placed', 'please', 'plus', 'possible', 'presumably', 'probably', 'provides', 'que', 'quite', 'qv', 'rather', 'rd', 're', 'really', 'reasonably', 'regarding', 'regardless', 'regards', 'relatively', 'respectively', 'right', 'said', 'same', 'saw', 'say', 'saying', 'says', 'second', 'secondly', 'see', 'seeing', 'seem', 'seemed', 'seeming', 'seems', 'seen', 'self', 'selves', 'sensible', 'sent', 'serious', 'seriously', 'seven', 'several', 'shall', 'she', 'should', \"shouldn't\", 'since', 'six', 'so', 'some', 'somebody', 'somehow', 'someone', 'something', 'sometime', 'sometimes', 'somewhat', 'somewhere', 'soon', 'sorry', 'specified', 'specify', 'specifying', 'still', 'sub', 'such', 'sup', 'sure', \"t's\", 'take', 'taken', 'tell', 'tends', 'th', 'than', 'thank', 'thanks', 'thanx', 'that', \"that's\", 'thats', 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'thence', 'there', \"there's\", 'thereafter', 'thereby', 'therefore', 'therein', 'theres', 'thereupon', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'think', 'third', 'this', 'thorough', 'thoroughly', 'those', 'though', 'three', 'through', 'throughout', 'thru', 'thus', 'to', 'together', 'too', 'took', 'toward', 'towards', 'tried', 'tries', 'truly', 'try', 'trying', 'twice', 'two', 'un', 'under', 'unfortunately', 'unless', 'unlikely', 'until', 'unto', 'up', 'upon', 'us', 'use', 'used', 'useful', 'uses', 'using', 'usually', 'value', 'various', 'very', 'via', 'viz', 'vs', 'want', 'wants', 'was', \"wasn't\", 'way', 'we', \"we'd\", \"we'll\", \"we're\", \"we've\", 'welcome', 'well', 'went', 'were', \"weren't\", 'what', \"what's\", 'whatever', 'when', 'whence', 'whenever', 'where', \"where's\", 'whereafter', 'whereas', 'whereby', 'wherein', 'whereupon', 'wherever', 'whether', 'which', 'while', 'whither', 'who', \"who's\", 'whoever', 'whole', 'whom', 'whose', 'why', 'will', 'willing', 'wish', 'with', 'within', 'without', \"won't\", 'wonder', 'would', \"wouldn't\", 'yes', 'yet', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves', 'zero', 'ourselves', 'out', 'over', 'own', 'same', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', \"shouldn't\", 'so', 'some', 'such', 'than', 'that', \"that's\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', \"there's\", 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 'very', 'was', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", \"we've\", 'were', \"weren't\", 'what', \"what's\", 'when', \"when's\", 'where', \"where's\", 'which', 'while', 'who', \"who's\", 'whom', 'why', \"why's\", 'with', \"won't\", 'would', \"wouldn't\", 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves', 'a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and', 'any', 'are', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', \"can't\", 'cannot', 'could', \"couldn't\", 'did', \"didn't\", 'do', 'does', \"doesn't\", 'doing', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', \"hadn't\", 'has', \"hasn't\", 'have', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", \"he's\", 'her', 'here', \"here's\", 'hers', 'herself', 'him', 'himself', 'his', 'how', \"how's\", 'i', \"i'd\", \"i'll\", \"i'm\", \"i've\", 'if', 'in', 'into', 'is', \"isn't\", 'it', \"it's\", 'its', 'itself', \"let's\", 'me', 'more', 'most', \"mustn't\", 'my', 'myself', 'no', 'nor', 'not', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'ought', 'our', 'ours', '&amp;', 'ji', 'india', 'delhi', 'shri', 'govt', 'pm', 'people', 'bjp', 'aap', 'inc', 'today', 'happy', 'modi', 'congress', 'minister', 'cm', 'covid', 'birthday', 'day', 'congratulations', 'government', 'president', 'indian', 'state', 'time', 'good', 'national', 'party', 'leader', 'live', 'farmers', 'country', 'great', 'nation', 'work']\n"
     ]
    }
   ],
   "source": [
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import warnings\n",
    "from bs4 import BeautifulSoup\n",
    "#from markdown import markdown\n",
    "\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U0001F1F2-\\U0001F1F4\"  # Macau flag\n",
    "        u\"\\U0001F1E6-\\U0001F1FF\"  # flags\n",
    "        u\"\\U0001F600-\\U0001F64F\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U0001F1F2\"\n",
    "        u\"\\U0001F1F4\"\n",
    "        u\"\\U0001F620\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u2640-\\u2642\"\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "\n",
    "text = emoji_pattern.sub(r'', text)\n",
    "\n",
    "\n",
    "remove_urls = lambda x: re.sub(\"http(.+)?(\\W|$)\", ' ', x)\n",
    "remove_RT = lambda x: x.replace(\"RT \", \"\")\n",
    "remove_mentions = lambda x: re.sub(\"@\\S+\", '', x)\n",
    "remove_hashtags = lambda x: re.sub(\"#\\S+\", '', x)\n",
    "remove_digits = lambda x: re.sub(\"\\d+\", \"\", x)\n",
    "remove_punct = lambda x: re.sub(\"!|\\||\\%|\\.|\\-|\\/|:|…|,|\\?|।+|'+\", \"\", x)\n",
    "remove_emojis = lambda x: emoji_pattern.sub(\"\", x)\n",
    "normalize_spaces = lambda x: re.sub(\"[\\n\\r\\t ]+\", ' ', x)\n",
    "remove_stop = lambda x: \" \".join(i for i in x.lower().split() if i not in stopwords)\n",
    "\n",
    "\n",
    "preproc_text = lambda x: remove_stop(\n",
    "                            normalize_spaces(\n",
    "                                remove_emojis(\n",
    "                                    remove_punct(\n",
    "                                        remove_digits(\n",
    "                                            remove_hashtags(\n",
    "                                                remove_mentions(\n",
    "                                                    remove_RT(\n",
    "                                                        remove_urls(x)))))))))\n",
    "\n",
    "frame['clean_text'] = frame['text'].parallel_apply(lambda x: preproc_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @narendramodi: Continuing the reform trajectory, the Cabinet has approved a PLI Scheme for the Auto Industry and Drone Industry. This wi… ['continuing', 'reform', 'trajectory', 'cabinet', 'approved', 'pli', 'scheme', 'auto', 'industry', 'drone', 'industry', 'wi']\n",
      "RT @amitmalviya: In 2018, Rajkumar Roy, a school teacher and father of 2, was found mutilated and dead after he resisted TMC’s booth captur… ['rajkumar', 'roy', 'school', 'teacher', 'father', 'mutilated', 'dead', 'resisted', 'tmc’s', 'booth', 'captur']\n",
      "@Mysteriousgrl_R @ Iske aage bhi kuchh likh dete 😂😂\n",
      "\n",
      "Aur lehnga pehle se hi taiyaar 😁😁 ['@', 'iske', 'aage', 'bhi', 'kuchh', 'likh', 'dete', 'aur', 'lehnga', 'pehle', 'se', 'taiyaar']\n",
      "RT @narendramodi: With our complementary strengths, India and US can creatively collaborate on a 2030 agenda for clean and green technologi… ['complementary', 'strengths', 'creatively', 'collaborate', 'agenda', 'clean', 'green', 'technologi']\n",
      "@myauditors like vivek Oberoi got :) ['vivek', 'oberoi', ')']\n"
     ]
    }
   ],
   "source": [
    "testFrame = frame.sample(5)\n",
    "for idx, row in testFrame.iterrows():\n",
    "    print(row['text'], row['clean_text'].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en ['continuing', 'reform', 'trajectory', 'cabinet', 'approved', 'pli', 'scheme', 'auto', 'industry', 'drone', 'industry', 'wi']\n",
      "en ['rajkumar', 'roy', 'school', 'teacher', 'father', 'mutilated', 'dead', 'resisted', 'tmc’s', 'booth', 'captur']\n",
      "hi ['@', 'iske', 'aage', 'bhi', 'kuchh', 'likh', 'dete', 'aur', 'lehnga', 'pehle', 'se', 'taiyaar']\n",
      "en ['complementary', 'strengths', 'creatively', 'collaborate', 'agenda', 'clean', 'green', 'technologi']\n",
      "ht ['vivek', 'oberoi', ')']\n"
     ]
    }
   ],
   "source": [
    "for idx, row in testFrame.iterrows():\n",
    "    print(row['language'], row['clean_text'].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hi', 'en', 'und', 'in', 'ne', 'mr', 'ht', 'tl', 'sv', 'et', 'te',\n",
       "       'bn', 'kn', 'vi', 'de', 'gu', 'es', 'ca', 'pl', 'or', 'pt', 'cs',\n",
       "       'sl', 'lv', 'ro', 'fr', 'nl', 'ur', 'pa', 'tr', 'is', 'cy', 'eu',\n",
       "       'it', 'lt', 'da', 'ta', 'fi', 'ml', 'no', 'hu', 'ar', 'ja', 'zh',\n",
       "       'iw', 'fa', 'uk', 'bo', 'ps', 'si', 'ru'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.language.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>party</th>\n",
       "      <th>language</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>None</td>\n",
       "      <td>@abhinaw121 @AnujBajpai_ @eurasiawale Number s...</td>\n",
       "      <td>INC</td>\n",
       "      <td>in</td>\n",
       "      <td>number send karo enka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>Divyachauhanbjp</td>\n",
       "      <td>RT @Upadhyaymayank5: @Divyachauhanbjp Janamdin...</td>\n",
       "      <td>INC</td>\n",
       "      <td>in</td>\n",
       "      <td>janamdin ki hardik shubhkamnaye apko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>Divyachauhanbjp</td>\n",
       "      <td>@AMISHDEVGAN We all Real Indians are with you ...</td>\n",
       "      <td>INC</td>\n",
       "      <td>in</td>\n",
       "      <td>real indians apka kaam ek nationalist journali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>Divyachauhanbjp</td>\n",
       "      <td>@papernirbandh Banke bihari bless you</td>\n",
       "      <td>INC</td>\n",
       "      <td>in</td>\n",
       "      <td>banke bihari bless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>Divyachauhanbjp</td>\n",
       "      <td>Heartiest Congratulations @ArunSinghbjp Ji Bha...</td>\n",
       "      <td>INC</td>\n",
       "      <td>in</td>\n",
       "      <td>heartiest bhai sahab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638245</th>\n",
       "      <td>BJP4Palamuru</td>\n",
       "      <td>RT @AvinashButtaBjp: #EcoFriendlyChristmas\\n\\n...</td>\n",
       "      <td>BJP</td>\n",
       "      <td>in</td>\n",
       "      <td>xmas tree telangana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638651</th>\n",
       "      <td>BJP4Palamuru</td>\n",
       "      <td>RT @Mayurmatam: Some iconic photos on Sardar P...</td>\n",
       "      <td>BJP</td>\n",
       "      <td>in</td>\n",
       "      <td>iconic photos sardar patel jayanti iron man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638864</th>\n",
       "      <td>BJP4Palamuru</td>\n",
       "      <td>RT @Mayurmatam: 🕉️🕉️Namah Shivaiah✡️✡️⚛️⚛️ htt...</td>\n",
       "      <td>BJP</td>\n",
       "      <td>in</td>\n",
       "      <td>namah shivaiah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639369</th>\n",
       "      <td>BJP4Palamuru</td>\n",
       "      <td>RT @drlaxmanbjp: Remembering former union mini...</td>\n",
       "      <td>BJP</td>\n",
       "      <td>in</td>\n",
       "      <td>remembering union padma vibhushan arun jaitely...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639404</th>\n",
       "      <td>BJP4Palamuru</td>\n",
       "      <td>RT @ksk_saadhu: Delhi london bangaya @Hyndavir...</td>\n",
       "      <td>BJP</td>\n",
       "      <td>in</td>\n",
       "      <td>london bangaya</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8377 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             screen_name                                               text  \\\n",
       "38                  None  @abhinaw121 @AnujBajpai_ @eurasiawale Number s...   \n",
       "428      Divyachauhanbjp  RT @Upadhyaymayank5: @Divyachauhanbjp Janamdin...   \n",
       "693      Divyachauhanbjp  @AMISHDEVGAN We all Real Indians are with you ...   \n",
       "733      Divyachauhanbjp              @papernirbandh Banke bihari bless you   \n",
       "1086     Divyachauhanbjp  Heartiest Congratulations @ArunSinghbjp Ji Bha...   \n",
       "...                  ...                                                ...   \n",
       "1638245     BJP4Palamuru  RT @AvinashButtaBjp: #EcoFriendlyChristmas\\n\\n...   \n",
       "1638651     BJP4Palamuru  RT @Mayurmatam: Some iconic photos on Sardar P...   \n",
       "1638864     BJP4Palamuru  RT @Mayurmatam: 🕉️🕉️Namah Shivaiah✡️✡️⚛️⚛️ htt...   \n",
       "1639369     BJP4Palamuru  RT @drlaxmanbjp: Remembering former union mini...   \n",
       "1639404     BJP4Palamuru  RT @ksk_saadhu: Delhi london bangaya @Hyndavir...   \n",
       "\n",
       "        party language                                         clean_text  \n",
       "38        INC       in                              number send karo enka  \n",
       "428       INC       in               janamdin ki hardik shubhkamnaye apko  \n",
       "693       INC       in  real indians apka kaam ek nationalist journali...  \n",
       "733       INC       in                                 banke bihari bless  \n",
       "1086      INC       in                               heartiest bhai sahab  \n",
       "...       ...      ...                                                ...  \n",
       "1638245   BJP       in                                xmas tree telangana  \n",
       "1638651   BJP       in        iconic photos sardar patel jayanti iron man  \n",
       "1638864   BJP       in                                     namah shivaiah  \n",
       "1639369   BJP       in  remembering union padma vibhushan arun jaitely...  \n",
       "1639404   BJP       in                                     london bangaya  \n",
       "\n",
       "[8377 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.loc[frame['language']=='in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'hi': 817077, 'en': 510354, 'und': 94975, 'mr': 65080, 'gu': 56482, 'kn': 24557, 'ta': 12811, 'pa': 10624, 'bn': 8596, 'in': 8377, 'te': 5738, 'or': 4243, 'ml': 3737, 'ne': 3735, 'tl': 3454, 'et': 2771, 'fr': 929, 'ht': 835, 'es': 681, 'it': 551, 'ca': 368, 'da': 360, 'ro': 338, 'nl': 307, 'pt': 287, 'tr': 285, 'de': 244, 'sv': 227, 'eu': 205, 'fi': 163, 'cs': 149, 'no': 143, 'lt': 116, 'pl': 109, 'sl': 107, 'hu': 102, 'vi': 96, 'lv': 94, 'ur': 85, 'cy': 83, 'is': 38, 'iw': 29, 'ja': 21, 'ar': 20, 'zh': 13, 'uk': 10, 'fa': 4, 'si': 3, 'ps': 2, 'bo': 1, 'ru': 1})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(frame['language'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'AAP': 506846, 'INC': 462235, 'BJP': 423430})\n"
     ]
    }
   ],
   "source": [
    "keep_lang = ['en','hi','mr']\n",
    "lang_frame = frame.loc[frame['language'].isin(keep_lang)]\n",
    "print(Counter(lang_frame['party'].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## phrasing based on languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "corp = lang_frame['clean_text'].tolist()\n",
    "parties = lang_frame['party'].tolist()\n",
    "corp_tokens = [c.split() for c in corp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = Phrases(corp_tokens, min_count=5, threshold=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSent = ['स्वर्णिम', 'दिवस', 'इतिहास', 'अंकित', 'चुका', 'क्योंकि', 'अयोध्या', 'भगवान', 'रामचंद्र', 'मंदिर', 'निर्माण', 'पुनीत']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['स्वर्णिम', 'दिवस', 'इतिहास', 'अंकित', 'चुका', 'क्योंकि', 'अयोध्या_भगवान', 'रामचंद्र', 'मंदिर_निर्माण', 'पुनीत']\n"
     ]
    }
   ],
   "source": [
    "print(phrases[testSent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokes = [phrases[t] for t in corp_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "BJP_data = []\n",
    "INC_data = []\n",
    "AAP_data = []\n",
    "\n",
    "for i in range(len(tokes)):\n",
    "    if parties[i]=='BJP':\n",
    "        BJP_data.append(tokes[i])\n",
    "    if parties[i]=='INC':\n",
    "        INC_data.append(tokes[i])\n",
    "    if parties[i]=='AAP':\n",
    "        AAP_data.append(tokes[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BJP topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "423430"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(BJP_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "BJP_id2word = corpora.Dictionary(BJP_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 2), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 2), (15, 1), (16, 1)]]\n"
     ]
    }
   ],
   "source": [
    "BJP_corpus = [BJP_id2word.doc2bow(text) for text in BJP_data]\n",
    "print(BJP_corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 36s, sys: 5min 14s, total: 12min 51s\n",
      "Wall time: 10min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import gensim\n",
    "BJP_model = gensim.models.ldamulticore.LdaMulticore(corpus=BJP_corpus,\n",
    "                                                    id2word=BJP_id2word,\n",
    "                                                    workers=128,\n",
    "                                                    num_topics=5,\n",
    "                                                    random_state=100,\n",
    "                                                    chunksize=100,\n",
    "                                                    passes=10,\n",
    "                                                    per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.002*\"राम\" + 0.002*\"namo_app\" + 0.001*\"days\" + 0.001*\"hai\" + 0.001*\"•\" + '\n",
      "  '0.001*\"support\" + 0.001*\"team\" + 0.001*\"bengal\" + 0.001*\"gujarat\" + '\n",
      "  '0.001*\"hospital\"'),\n",
      " (1,\n",
      "  '0.002*\"namo_app\" + 0.002*\"\"\" + 0.001*\"आभार\" + 0.001*\"कामना\" + '\n",
      "  '0.001*\"wishes\" + 0.001*\"उत्तम_स्वास्थ्य\" + 0.001*\"watch\" + '\n",
      "  '0.001*\"ईश्वर_आपके\" + 0.001*\"ईश्वर_प्रार्थना\" + 0.001*\"ॐ_शांति\"'),\n",
      " (2,\n",
      "  '0.001*\"दिवस\" + 0.001*\"assam\" + 0.001*\"पीएम\" + 0.001*\"लोग\" + '\n",
      "  '0.001*\"राजस्थान\" + 0.001*\"namo_app\" + 0.001*\"स्वतंत्रता_संग्राम\" + '\n",
      "  '0.001*\"अवसर\" + 0.001*\"सादर\" + 0.001*\"माननीय\"'),\n",
      " (3,\n",
      "  '0.001*\"शुभकामनाओं_धन्यवाद\" + 0.001*\"सब\" + 0.001*\"sir\" + 0.001*\"पीएम\" + '\n",
      "  '0.001*\"आदरणीय\" + 0.001*\"नाम\" + 0.001*\"होगा\" + 0.001*\"कभी\" + 0.001*\"आ\" + '\n",
      "  '0.001*\"चाहिए\"'),\n",
      " (4,\n",
      "  '0.006*\"धन्यवाद\" + 0.002*\"app\" + 0.002*\"आपकी_शुभकामनाओं\" + '\n",
      "  '0.002*\"युवा_मोर्चा\" + 0.001*\"शुभकामनाओं_सादर\" + 0.001*\"आदरणीय\" + '\n",
      "  '0.001*\"namo_app\" + 0.001*\"आ\" + 0.001*\"mumbai\" + 0.001*\"()\"')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(BJP_model.print_topics())\n",
    "doc_lda = BJP_model[BJP_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
